================================================================================
            MLflow Project-Specific AWS Credentials - Summary
================================================================================

✅ PROBLEM SOLVED: No More Credential Conflicts!
-------------------------------------------------

Your MLflow project can now use its own AWS credentials that WON'T interfere
with your other AWS projects.

HOW IT WORKS
------------

The system checks for credentials in this priority order:

  1. MLFLOW_AWS_ACCESS_KEY_ID       (project-specific) ← HIGHEST PRIORITY
  2. AWS_ACCESS_KEY_ID               (global) ← Fallback

Same for SECRET_ACCESS_KEY and DEFAULT_REGION.

OPTION 1: Using .env File (Recommended)
----------------------------------------

Create .env in the project root:

  # .env
  MLFLOW_ARTIFACT_ROOT=s3://my-mlflow-bucket/artifacts
  MLFLOW_AWS_ACCESS_KEY_ID=your-mlflow-key
  MLFLOW_AWS_SECRET_ACCESS_KEY=your-mlflow-secret
  MLFLOW_AWS_DEFAULT_REGION=us-east-1

✅ Automatically loaded - no manual sourcing!
✅ Already in .gitignore - safe from commits
✅ Won't affect other AWS projects

OPTION 2: Using Environment Variables
--------------------------------------

  # Set project-specific credentials
  export MLFLOW_AWS_ACCESS_KEY_ID="mlflow-key"
  export MLFLOW_AWS_SECRET_ACCESS_KEY="mlflow-secret"
  export MLFLOW_ARTIFACT_ROOT="s3://bucket/artifacts"

  # Your global credentials can coexist
  export AWS_ACCESS_KEY_ID="main-project-key"
  export AWS_SECRET_ACCESS_KEY="main-project-secret"

✅ MLFLOW_AWS_* takes precedence
✅ AWS_* remains available for other tools

QUICK START (2 Minutes)
------------------------

Step 1: Create .env file

  cd /home/ubuntu/basketworld
  cat > .env << 'EOF'
  MLFLOW_ARTIFACT_ROOT=s3://your-bucket/mlflow-artifacts
  MLFLOW_AWS_ACCESS_KEY_ID=your-mlflow-key
  MLFLOW_AWS_SECRET_ACCESS_KEY=your-mlflow-secret
  MLFLOW_AWS_DEFAULT_REGION=us-east-1
  EOF

Step 2: Start MLflow server

  mlflow server \
    --backend-store-uri sqlite:///mlflow.db \
    --default-artifact-root s3://your-bucket/mlflow-artifacts \
    --port 5000

Step 3: Run training

  python train/train.py --mlflow-experiment-name test

  Output will show:
    MLflow Configuration:
      Tracking URI: http://localhost:5000
      Storage Type: S3 (Remote)
      AWS Credentials: project-specific (MLFLOW_AWS_*)  ← See this!
      AWS Region: us-east-1

VERIFICATION
------------

Test 1: Check configuration

  python -c "from basketworld.utils.mlflow_config import get_mlflow_config; print(get_mlflow_config())"

Test 2: Run full test

  python scripts/test_mlflow_s3.py

Test 3: Run demo

  bash scripts/demo_project_credentials.sh

WHAT'S DIFFERENT NOW?
---------------------

Before:
  • Had to use global AWS_* credentials
  • Conflicted with other AWS projects
  • Couldn't have different AWS accounts per project

After:
  ✅ Use MLFLOW_AWS_* for this project only
  ✅ Keep AWS_* for your main project
  ✅ No conflicts!
  ✅ Automatically loaded from .env
  ✅ Works with all scripts (training, analytics, backend)

EXAMPLE SCENARIO
----------------

Terminal 1: Your main AWS project
  cd /home/ubuntu/main-project
  export AWS_ACCESS_KEY_ID="main-key"
  export AWS_SECRET_ACCESS_KEY="main-secret"
  python main.py  # Uses global AWS credentials

Terminal 2: MLflow basketworld project
  cd /home/ubuntu/basketworld
  # .env has MLFLOW_AWS_* credentials
  python train/train.py  # Uses project-specific credentials from .env

✅ Both work independently! No conflicts!

KEY FILES
---------

Configuration Module:
  basketworld/utils/mlflow_config.py
  - Automatic .env file loading
  - Credential precedence logic
  - boto3 environment setup

Documentation:
  docs/mlflow_project_credentials.md       (Full guide)
  docs/mlflow_s3_quickstart.md             (Quick reference)
  docs/mlflow_s3_setup.md                  (Complete setup)
  
Example Files:
  .env.mlflow.example                      (Template)
  
Scripts:
  scripts/demo_project_credentials.sh      (Interactive demo)
  scripts/test_mlflow_s3.py                (Validation test)

CREDENTIAL PRECEDENCE SUMMARY
------------------------------

For AWS Access Key:
  1. MLFLOW_AWS_ACCESS_KEY_ID (from .env or environment)
  2. AWS_ACCESS_KEY_ID (global)

For AWS Secret Key:
  1. MLFLOW_AWS_SECRET_ACCESS_KEY (from .env or environment)
  2. AWS_SECRET_ACCESS_KEY (global)

For AWS Region:
  1. MLFLOW_AWS_DEFAULT_REGION (from .env or environment)
  2. AWS_DEFAULT_REGION (global)
  3. Default: us-east-1

ALL SCRIPTS SUPPORT THIS
-------------------------

✅ train/train.py
✅ app/backend/main.py
✅ analytics/elo_evolution.py
✅ analytics/evaluate.py
✅ analytics/heatmap.py
✅ analytics/shotchart.py
✅ analytics/assist_skill_delta.py
✅ analytics/trajectory_accumulation.py
✅ scripts/cleanup_mlflow_deleted_runs.py

All automatically detect and use project-specific credentials!

SECURITY
--------

✅ .env is in .gitignore - won't be committed
✅ Project-specific credentials isolate risk
✅ Can use separate IAM user for MLflow
✅ Least-privilege IAM policies recommended

TROUBLESHOOTING
---------------

Issue: Still using global credentials
Fix: Make sure you're using MLFLOW_AWS_* prefix, not just AWS_*

Issue: .env not loading
Fix: Ensure file is named exactly ".env" (not ".env.txt")
      and is in project root (/home/ubuntu/basketworld/.env)

Issue: Credentials conflict
Fix: Use MLFLOW_AWS_* prefix to isolate from global credentials

See docs/mlflow_project_credentials.md for detailed troubleshooting.

SUMMARY
-------

✅ Create .env file with MLFLOW_AWS_* credentials
✅ No manual sourcing - automatically loaded
✅ No conflicts with other AWS projects
✅ Works with all scripts
✅ Secure - .env in .gitignore
✅ Can have different AWS account per project

Ready to use in 2 minutes!

================================================================================

